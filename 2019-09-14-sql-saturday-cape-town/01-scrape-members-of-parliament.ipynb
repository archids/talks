{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.exegetic.biz/img/exegetic-banner-black.svg\" width=\"35%\" align=\"right\">\n",
    "\n",
    "# Web Scraping: Members of Parliament\n",
    "\n",
    "Andrew B. Collier (@datawookie | andrew@exegetic.biz)<br>\n",
    "Data Scientist / Founder<br>\n",
    "[Exegetic Analytics](https://www.exegetic.biz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #3498db;\">**↯ Notebooks**</span> available from https://bit.ly/2kxOTT9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial we're going to scrape (public) details of our esteemed members of parliament from the website of the [Parliamentary Monitoring Group](https://pmg.org.za/).\n",
    "\n",
    "![](fig/members-of-parliament.png)\n",
    "\n",
    "**The Brief**: Our brief is to capture data for all members and store it in a relational database. Why? Well, suppose you were developing an insurance or investment product targeted specifically at politicians, then this would immediately give you a list of prospects with their contact details.\n",
    "\n",
    "**The Challenge**: There's an index page with links to individual pages for each of the members. Need to systematically scrape all of the member pages.\n",
    "\n",
    "**The Approach:** These are the steps that we'll take to achieve that goal:\n",
    "\n",
    "1. Manually scrape the data for a specific member.\n",
    "2. Write a function to scrape the data for a specific member.\n",
    "3. Test that function.\n",
    "4. Run the function across all of the members.\n",
    "5. Store the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "Load some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import re, random, time, sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/datawookie/useful-images/raw/master/banner/web-scraping-python.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping packages\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components to a scrape:\n",
    "\n",
    "- retrieving the HTML content of the page (done with the `requests` package) and\n",
    "- parsing the page and extracting data (done with the `BeautifulSoup` package)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Synchronise your watches (or your RNGs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the SQLite database that we'll use to store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLITEDB = 'members-of-parliament.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [this link](https://pmg.org.za/members/) in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An index of the members, with a thumbnail linking to their individual profile pages.\n",
    "URL = 'https://pmg.org.za/members/'\n",
    "# A page for a specific member.\n",
    "url = 'https://www.pa.org.za/person/alexandra-lilian-amelia-abrahams/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Scrape\n",
    "\n",
    "Grab the HTML for a specific member's page. This uses a HTTP `GET` request. This is functionally equivalent to opening the URL in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check whether the request was successful. The result below is a [HTTP status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes), where 200 indicates success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.\n",
    "\n",
    "Let's take a look at the response headers (essentially metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we've received an HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers['Content-Type'].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can take a look at the actual content of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty complicated! Maybe one of the reasons for the term [\"tag soup\"](https://en.wikipedia.org/wiki/Tag_soup). Not to worry! We'll be using simple tools to parse the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(response.content, 'html.parser')\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superficially the document looks cleaner. However, the `BeautifulSoup` objects puts a slew of additional functionality at our disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap all of that up in a function which will reliably return parsed HTML for a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(url):\n",
    "    try:\n",
    "        # Use closing() to ensure that network resources are freed up after leaving context.\n",
    "        response = get(url, stream=True)\n",
    "        #\n",
    "        status_code  = response.status_code\n",
    "        content_type = response.headers['Content-Type'].lower()\n",
    "    except RequestException as e:\n",
    "        print('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "    \n",
    "    if status_code == 200 and content_type is not None and content_type.find('html') > -1:\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it a test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = read_html(url)\n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "\n",
    "Start by retrieving the person's name. Need to get the appropriate CSS selector. In this case it's easy: it's the only `<h1>` tag on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.select('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select()` method returns *all* tags which match the selector. If we want just the first one then use the `select_one()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.select_one('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(person.select_one('h1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the text enclosed by the tag then we access the `text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person \\\n",
    "    .select_one('h1') \\\n",
    "    .text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #3498db;\">**↯ Exercise**</span> Raw scraped data are often grubby. Remove excess whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# Your code goes here.\n",
    "#\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "person.select_one('h1').text \\\n",
    "    .strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliation\n",
    "\n",
    "Next let's get party affiliation. This information is in an `<a>` tag but it's the only tag on the page which has the `party-membership--party` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation = person.select_one('.party-membership--party')\n",
    "affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to dig into the tag object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation.attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Address\n",
    "\n",
    "Now let's get the email address. The address is in a `<a>` tag nested inside a `<span>` with class `email-address`. There might be multiple email addresses, so here we use `select()` to capture all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.select('.email-address a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the text for each tag using a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a.text for a in person.select('.email-address a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #3498db;\">**↯ Exercise**</span> Concatenate multiple email addresses with a semicolon separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# Your code goes here.\n",
    "#\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "'; '.join([a.text for a in person.select('.email-address a')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phone Number\n",
    "\n",
    "Extracing the phone number requires a slightly more sophisticated selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.select('a[href^=\"tel:\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we need to cater for multiple phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'; '.join([a.text for a in person.select('[href^=\"tel:\"]')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good progress, but if we want to do this systematically across all members then we'll need to write another function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Function\n",
    "\n",
    "The function should accept an URL and return a dictionary with the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person(url):\n",
    "    person = read_html(url)\n",
    "    #\n",
    "    if person is None:\n",
    "        return None\n",
    "    else:\n",
    "        return {\n",
    "            'name': person.select_one('h1').text.strip(),\n",
    "            'party': person.select_one('.party-membership--party').text,\n",
    "            'phone': '; '.join([a.text for a in person.select('[href^=\"tel:\"]')]),\n",
    "            'email': '; '.join([a.text for a in person.select('.email-address a')])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a few quick tests on the following members:\n",
    "\n",
    "- [Alexandra Lilian Amelia Abrahams](https://www.pa.org.za/person/alexandra-lilian-amelia-abrahams/)\n",
    "- [Rachel Cecilia Adams](https://www.pa.org.za/person/rachel-cecilia-adams/) and\n",
    "- [Mr Michael Bagraim](https://www.pa.org.za/person/michael-bagraim/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_person('https://www.pa.org.za/person/alexandra-lilian-amelia-abrahams/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_person('https://www.pa.org.za/person/rachel-cecilia-adams/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_person('https://www.pa.org.za/person/michael-bagraim/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those all look good. I think we're ready to start scraping at scale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping All Members\n",
    "\n",
    "First get the HTML for the index page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = read_html(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all of the URLs for members' pages. These URLs are in `<div>` tags with `single-mp` class. Within the `<div>` is an `<a>` linking to the member page.\n",
    "\n",
    "Let's start by looking at a single anchor tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory.select_one('.single-mp a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to iterate over all of these tags and extract the `href` attribute from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parliament = [a.attrs['href'] for a in directory.select('.single-mp a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many links?\n",
    "#\n",
    "len(parliament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first few links.\n",
    "#\n",
    "parliament[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only URLs which are on <https://www.pa.org.za/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_url = re.compile('^https://www.pa.org.za/')\n",
    "\n",
    "parliament = [url for url in parliament if pattern_url.match(url)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parliament)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now iterate over a random subset of URLs, scraping each one in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "#\n",
    "members = [get_person(url) for url in random.sample(parliament, 20)]\n",
    "#\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time: %.3fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #3498db;\">**↯ Exercise**</span> Make the code above a little more server-friendly by introducing a delay. *Hint:* Use `time.sleep()` to pause and `np.random.poisson()` to sample a random number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# Your code goes here.\n",
    "#\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def get_person_delay(url, mean):\n",
    "    time.sleep(np.random.poisson(mean))\n",
    "    return get_person(url)\n",
    "\n",
    "tic = time.time()\n",
    "#\n",
    "# Sleep (on average) 5 seconds before retrieving URL.\n",
    "members = [get_person_delay(url, 5)for url in random.sample(parliament, 20)]\n",
    "#\n",
    "toc = time.time()\n",
    "\n",
    "print('Elapsed time: %.3fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records without data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [m for m in members if m is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.DataFrame(members)\n",
    "members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there we have the contact details of members of parliament.\n",
    "\n",
    "Parliament is by no means static. Members come and go. Since we have a script though, we just have to run the script again to update the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database\n",
    "\n",
    "To finish off we'll save the data to a [SQLite](https://www.sqlite.org/index.html) database.\n",
    "\n",
    "Use a context manager to ensure that the connection to the database is closed neatly after the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(SQLITEDB) as db:\n",
    "    members.to_sql('members', db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be good to check on the content of the database. You can download a local copy as follows:\n",
    "\n",
    "- select File ⟶ Open;\n",
    "- check the box next to the file you've just created; and\n",
    "- press the Download button.\n",
    "\n",
    "You can open the file with something like [DB Browser for SQLite](https://sqlitebrowser.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
